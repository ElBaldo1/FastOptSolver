{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c62c3d43",
   "metadata": {},
   "source": [
    "Setup: Imports & Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41298b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Data generation utilities\n",
    "from easy_boston_data import (\n",
    "    generate_correlated_boston_like_data,\n",
    "    generate_easy_boston_like_data\n",
    ")\n",
    "\n",
    "# Core solvers\n",
    "from iterative_solvers import ista, fista, fista_delta\n",
    "from lbfgs import LBFGSSolver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cd410c",
   "metadata": {},
   "source": [
    "Preprocessing & Regularization Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f807b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.1 Generate correlated data & standardize\n",
    "A, b, x_true = generate_correlated_boston_like_data(m=800, seed=42, noise_std=0.1)\n",
    "A = (A - A.mean(axis=0)) / A.std(axis=0)\n",
    "b = b - b.mean()\n",
    "\n",
    "# 3.1.2 Define regularization scenarios\n",
    "basic_regs = [\n",
    "    {'name':'lasso',      'alpha1':1.0,   'alpha2':0.0},\n",
    "    {'name':'elasticnet', 'alpha1':1.0,   'alpha2':1.0},\n",
    "    {'name':'lasso',      'alpha1':0.5,   'alpha2':0.0},\n",
    "    {'name':'elasticnet', 'alpha1':0.2,   'alpha2':0.05},\n",
    "    {'name':'elasticnet', 'alpha1':1e-4,  'alpha2':0.5}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fbb99e",
   "metadata": {},
   "source": [
    "Baseline: ISTA vs FISTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301577e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from objective_functions import compute_objective\n",
    "from prox_operators import prox_l1, prox_elastic_net\n",
    "from iterative_solvers import estimate_lipschitz\n",
    "\n",
    "records = []\n",
    "n, m = A.shape[1], A.shape[0]\n",
    "for reg in basic_regs:\n",
    "    name, a1, a2 = reg['name'], reg['alpha1'], reg['alpha2']\n",
    "    # Define smooth part g and its gradient grad_g, and prox_h for h\n",
    "    if name == 'lasso':\n",
    "        def g(x):\n",
    "            r = A @ x - b\n",
    "            return 0.5 * r.dot(r)\n",
    "        def grad_g(x):\n",
    "            return A.T @ (A @ x - b)\n",
    "        prox_h = lambda v, t: prox_l1(v, t * a1)\n",
    "        L0 = estimate_lipschitz(A)\n",
    "        L = L0\n",
    "    elif name == 'elasticnet':\n",
    "        def g(x):\n",
    "            r = A @ x - b\n",
    "            return 0.5 * r.dot(r) + a2 * x.dot(x)\n",
    "        def grad_g(x):\n",
    "            return A.T @ (A @ x - b) + 2 * a2 * x\n",
    "        prox_h = lambda v, t: prox_elastic_net(v, t, a1, a2)\n",
    "        L0 = estimate_lipschitz(A)\n",
    "        L = L0 + 2 * a2\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Initial point\n",
    "    x0 = np.zeros(n)\n",
    "    # Run ISTA with history to get iterates\n",
    "    t_start = time.perf_counter()\n",
    "    x_i, hist_i = ista(\n",
    "        x0, g, grad_g, prox_h, L,\n",
    "        backtracking=False, t_init=None,\n",
    "        max_iter=500, tol=0.0,\n",
    "        return_history=True\n",
    "    )\n",
    "    t_ista = time.perf_counter() - t_start\n",
    "\n",
    "    # Compute objective history for ISTA\n",
    "    obj_i = [compute_objective(xk, A, b, name, a1, a2) for xk in hist_i['x']]\n",
    "\n",
    "    # Run FISTA\n",
    "    t_start = time.perf_counter()\n",
    "    x_f, obj_f = fista(A, b, name, a1, a2, max_iter=500)\n",
    "    t_fista = time.perf_counter() - t_start\n",
    "\n",
    "    # Convergence plot\n",
    "    f_star = obj_f[-1]\n",
    "    ks_i = np.arange(1, len(obj_i) + 1)\n",
    "    ks_f = np.arange(1, len(obj_f) + 1)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.loglog(ks_i, np.minimum.accumulate(np.array(obj_i) - f_star), '-', label='ISTA')\n",
    "    plt.loglog(ks_f, np.minimum.accumulate(np.array(obj_f) - f_star), '-', label='FISTA')\n",
    "    plt.title(f\"Convergence: ISTA vs FISTA with {name.title()} (α₁={a1}, α₂={a2})\")\n",
    "    plt.xlabel('Iteration number $k$')\n",
    "    plt.ylabel('Suboptimality: $f(x) - f^*$')\n",
    "    plt.grid(True, which='both', ls='--', lw=0.5)\n",
    "    plt.legend(title='Method')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Record summary\n",
    "    records += [\n",
    "        {'method':'ISTA',  'regularizer':name, 'alpha1':a1, 'alpha2':a2,\n",
    "         'iterations':len(obj_i), 'runtime_s':t_ista},\n",
    "        {'method':'FISTA', 'regularizer':name, 'alpha1':a1, 'alpha2':a2,\n",
    "         'iterations':len(obj_f), 'runtime_s':t_fista}\n",
    "    ]\n",
    "\n",
    "df_basic = pd.DataFrame(records)\n",
    "print(df_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67017919",
   "metadata": {},
   "source": [
    "Advanced: ISTA Stopping & FISTA Adaptive-Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901117a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced experiments with ISTA stopping criterion and FISTA adaptive-restart\n",
    "adv_results = []\n",
    "tol = 1e-6\n",
    "\n",
    "for reg in basic_regs:\n",
    "    name, a1, a2 = reg['name'], reg['alpha1'], reg['alpha2']\n",
    "    if name == 'ridge':\n",
    "        continue\n",
    "\n",
    "    # Define g, grad_g, prox_h, L as in Section 3.2\n",
    "    if name == 'lasso':\n",
    "        def g(x): return 0.5 * np.linalg.norm(A @ x - b)**2\n",
    "        def grad_g(x): return A.T @ (A @ x - b)\n",
    "        prox_h = lambda v, t: prox_l1(v, t * a1)\n",
    "        L0 = estimate_lipschitz(A)\n",
    "        L = L0\n",
    "    else:  # elasticnet\n",
    "        def g(x): return 0.5 * np.linalg.norm(A @ x - b)**2 + a2 * x.dot(x)\n",
    "        def grad_g(x): return A.T @ (A @ x - b) + 2 * a2 * x\n",
    "        prox_h = lambda v, t: prox_elastic_net(v, t, a1, a2)\n",
    "        L0 = estimate_lipschitz(A)\n",
    "        L = L0 + 2 * a2\n",
    "\n",
    "    # Initial guess\n",
    "    x0 = np.zeros(n)\n",
    "\n",
    "    # ISTA with stopping (backtracking can be enabled if desired)\n",
    "    t0 = time.perf_counter()\n",
    "    x_i2, hist_i2 = ista(\n",
    "        x0, g, grad_g, prox_h, L,\n",
    "        backtracking=False,\n",
    "        t_init=None,\n",
    "        max_iter=500,\n",
    "        tol=tol,\n",
    "        return_history=True\n",
    "    )\n",
    "    t_ista2 = time.perf_counter() - t0\n",
    "    step_i2 = hist_i2['step_sizes']\n",
    "    xhist_i2 = hist_i2['x']\n",
    "\n",
    "    # FISTA with adaptive restart and stopping\n",
    "    t0 = time.perf_counter()\n",
    "    x_f2, obj_f2, step_f2, ratio_f2, xhist_f2 = fista(\n",
    "        A, b, name, a1, a2,\n",
    "        max_iter=500,\n",
    "        tol=tol,\n",
    "        adaptive_restart=True,\n",
    "        restart_threshold=1.0,\n",
    "        return_history=True\n",
    "    )\n",
    "    t_fista2 = time.perf_counter() - t0\n",
    "\n",
    "    adv_results += [\n",
    "        {\n",
    "            'method': 'ISTA+stop',\n",
    "            'regularizer': name,\n",
    "            'time_s': t_ista2,\n",
    "            'step_norms': step_i2,\n",
    "            'x_hist': xhist_i2\n",
    "        },\n",
    "        {\n",
    "            'method': 'FISTA+restart',\n",
    "            'regularizer': name,\n",
    "            'time_s': t_fista2,\n",
    "            'step_norms': step_f2,\n",
    "            'ratio_vals': ratio_f2,\n",
    "            'x_hist': xhist_f2\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# Plot step-norms for ISTA+stop\n",
    "plt.figure(figsize=(6,4))\n",
    "for run in adv_results:\n",
    "    if run['method']=='ISTA+stop':\n",
    "        plt.semilogy(run['step_norms'], label=run['regularizer'])\n",
    "plt.title('ISTA with Stopping: Step Norms vs Iteration')\n",
    "plt.xlabel('Iteration number $k$')\n",
    "plt.ylabel(r'Step norm $\\|x^{k+1}-x^k\\|$')\n",
    "plt.grid(True, which='both', ls='--', lw=0.5)\n",
    "plt.legend(title='Regularizer')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Plot step-norms for FISTA+restart\n",
    "plt.figure(figsize=(6,4))\n",
    "for run in adv_results:\n",
    "    if run['method']=='FISTA+restart':\n",
    "        plt.semilogy(run['step_norms'], label=run['regularizer'])\n",
    "plt.title('FISTA with Adaptive Restart: Step Norms vs Iteration')\n",
    "plt.xlabel('Iteration number $k$')\n",
    "plt.ylabel(r'Step norm $\\|x^{k+1}-x^k\\|$')\n",
    "plt.grid(True, which='both', ls='--', lw=0.5)\n",
    "plt.legend(title='Regularizer')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Plot adaptive-restart ratio\n",
    "plt.figure(figsize=(6,4))\n",
    "for run in adv_results:\n",
    "    if run['method']=='FISTA+restart':\n",
    "        plt.semilogy(run['ratio_vals'], label=run['regularizer'])\n",
    "plt.axhline(1.0, linestyle='--', linewidth=1, color='gray')\n",
    "plt.title('FISTA Adaptive Restart: Ratio $\\|Δx_k\\|/\\|Δx_{k-1}\\|$')\n",
    "plt.xlabel('Iteration number $k$')\n",
    "plt.ylabel(r'Ratio $\\|x^{k+1}-x^k\\|/ \\|x^k-x^{k-1}\\|$')\n",
    "plt.grid(True, which='both', ls='--', lw=0.5)\n",
    "plt.legend(title='Regularizer')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcfb44d",
   "metadata": {},
   "source": [
    "Ridge Regression via L-BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c366a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and run L-BFGS solver for Ridge\n",
    "ridge_solver = LBFGSSolver(reg_type='ridge', alpha1=0.0, alpha2=1.0, max_iter=500, tol=1e-6)\n",
    "# Measure runtime\n",
    "tr0 = time.perf_counter()\n",
    "ridge_solver.fit(A, b)\n",
    "tridge = time.perf_counter() - tr0\n",
    "\n",
    "# Plot convergence envelope of L-BFGS for Ridge\n",
    "ks_r = np.arange(1, len(ridge_solver.history_) + 1)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.loglog(\n",
    "    ks_r,\n",
    "    np.minimum.accumulate(np.array(ridge_solver.history_) - ridge_solver.final_obj_),\n",
    "    '-', label=f\"L-BFGS Ridge (α₁=0.0, α₂=1.0)\"\n",
    ")\n",
    "plt.title(\"Convergence: Ridge Regression via L-BFGS (α₁=0.0, α₂=1.0)\")\n",
    "plt.xlabel('Iteration number $k$')\n",
    "plt.ylabel('Suboptimality: $f(x) - f^*$')\n",
    "plt.grid(True, which='both', ls='--', lw=0.5)\n",
    "plt.legend(title='Method')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Append summary to records\n",
    "ridge_summary = {\n",
    "    'method': 'L-BFGS',\n",
    "    'regularizer': 'ridge',\n",
    "    'alpha1': 0.0,\n",
    "    'alpha2': 1.0,\n",
    "    'iterations': len(ridge_solver.history_),\n",
    "    'runtime_s': tridge\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcd18bd",
   "metadata": {},
   "source": [
    "FISTA vs FISTA-Delta Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e480f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare standard FISTA and FISTA-Delta for Lasso and ElasticNet cases\n",
    "variants = []\n",
    "delta = 3.0\n",
    "for reg in basic_regs:\n",
    "    name, a1, a2 = reg['name'], reg['alpha1'], reg['alpha2']\n",
    "    if name not in ('lasso','elasticnet') or a1 <= 0.0:\n",
    "        continue\n",
    "    # Standard FISTA\n",
    "    t0 = time.perf_counter()\n",
    "    x_std, obj_std = fista(A, b, name, a1, a2, max_iter=500)\n",
    "    t_std = time.perf_counter() - t0\n",
    "    # FISTA-Delta\n",
    "    t0 = time.perf_counter()\n",
    "    x_del, obj_del = fista_delta(A, b, name, a1, a2, delta=delta, max_iter=500)\n",
    "    t_del = time.perf_counter() - t0\n",
    "    # Estimate best f*\n",
    "    f_star = min(obj_std[-1], obj_del[-1])\n",
    "    # Plot convergence envelopes\n",
    "    ks_std = np.arange(1, len(obj_std)+1)\n",
    "    ks_del = np.arange(1, len(obj_del)+1)\n",
    "    env_std = np.minimum.accumulate(np.array(obj_std) - f_star)\n",
    "    env_del = np.minimum.accumulate(np.array(obj_del) - f_star)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.loglog(ks_std, env_std, '-', label=f\"FISTA standard (α₁={a1}, α₂={a2})\")\n",
    "    plt.loglog(ks_del, env_del, '-', label=f\"FISTA-Δ δ={delta} (α₁={a1}, α₂={a2})\")\n",
    "    plt.title(f\"FISTA vs FISTA-Δ Convergence: {name.title()} (α₁={a1}, α₂={a2})\")\n",
    "    plt.xlabel('Iteration number $k$')\n",
    "    plt.ylabel('Suboptimality: $f(x) - f^*$')\n",
    "    plt.grid(True, which='both', ls='--', lw=0.5)\n",
    "    plt.legend(title='Method')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # Record summary\n",
    "    variants += [\n",
    "        {'method':'FISTA','delta':None,'regularizer':name,'alpha1':a1,'alpha2':a2,'iterations':len(obj_std),'runtime_s':t_std},\n",
    "        {'method':'FISTA-DELTA','delta':delta,'regularizer':name,'alpha1':a1,'alpha2':a2,'iterations':len(obj_del),'runtime_s':t_del}\n",
    "    ]\n",
    "# Aggregate variant results into DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
