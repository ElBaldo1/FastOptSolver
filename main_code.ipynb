{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 0 — Setup & Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Solver Benchmark\n",
    "\n",
    "This notebook demonstrates the implementation and performance comparison of various optimization algorithms for solving regularized linear regression problems.\n",
    "\n",
    "We test:\n",
    "- ISTA (Iterative Soft-Thresholding Algorithm)\n",
    "- FISTA (Fast ISTA)\n",
    "- Gradient Descent (as a baseline)\n",
    "- (Optionally) L-BFGS for smooth problems\n",
    "\n",
    "The models handled include:\n",
    "- LASSO (ℓ₁-regularized least squares)\n",
    "- Ridge (ℓ₂-regularized least squares)\n",
    "- Elastic Net (ℓ₁ + ℓ₂ regularization)\n",
    "\n",
    "---\n",
    "\n",
    "This notebook relies on external modular implementations found in the `prox/` and `solvers/` directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- Prox operators ---\n",
    "from prox.prox_l1 import prox_l1\n",
    "from prox.prox_l2 import prox_l2\n",
    "\n",
    "# --- Solvers ---\n",
    "from solvers.ista import ista\n",
    "from solvers.fista import fista\n",
    "from solvers.gradient import gradient_descent\n",
    "from solvers.lbfgs import lbfgs_solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 1 — Dataset Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Loading & Preprocessing\n",
    "\n",
    "In this project, we aim to benchmark iterative optimization algorithms for regularized regression problems using a real-world dataset.\n",
    "\n",
    "To ensure that regularization plays a meaningful role and aligns with the project requirements, we select a dataset that:\n",
    "- represents a **supervised regression task** with a **continuous target variable**,\n",
    "- has a **sufficient number of features** (ideally moderate to high dimensionality),\n",
    "- includes **real-world, non-synthetic data**, e.g., from Kaggle or UCI repositories,\n",
    "- benefits from **regularization techniques** such as LASSO or Elastic Net,\n",
    "- and requires basic **preprocessing**, including normalization and potentially imputation.\n",
    "\n",
    "The dataset is loaded from a local CSV file, and we apply:\n",
    "- feature/target separation,\n",
    "- standardization of the input features,\n",
    "- and an 80/20 train-test split.\n",
    "\n",
    "Additional dataset-related discussion and justification will be included in the technical report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Load dataset (customize this part!) ---\n",
    "dataset_path = Path(\"Housing.csv\")\n",
    "df = pd.read_csv(dataset_path)\n",
    "print(df.columns)\n",
    "\n",
    "# --- Configure target and features ---\n",
    "target_column = \"price\"\n",
    "feature_columns = [col for col in df.columns if col != target_column]\n",
    "\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "feature_names = df_encoded.drop(columns=[target_column]).columns.tolist()\n",
    "\n",
    "X = df_encoded.drop(columns=[target_column]).values\n",
    "y = df_encoded[target_column].values\n",
    "\n",
    "# --- Standardize features ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- Train/test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Confirm shapes ---\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Demonstrating Proximity Operators\n",
    "\n",
    "Before using them in the solver, we visually inspect the behavior of:\n",
    "\n",
    "- ℓ₁ Prox (soft-thresholding)\n",
    "- ℓ₂ Prox (shrinkage)\n",
    "- Elastic Net Prox (combination)\n",
    "\n",
    "We apply them to a small vector `v` and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prox.demo_prox import demo_prox_operators\n",
    "\n",
    "demo_prox_operators()\n",
    "\n",
    "# --- Visual comparison of proximal operators ---\n",
    "v = np.linspace(-3, 3, 500)\n",
    "lam = 1.0\n",
    "alpha = 0.5\n",
    "\n",
    "prox_l1_vals = prox_l1(v, lam)\n",
    "prox_l2_vals = prox_l2(v, lam)\n",
    "from prox.prox_elasticnet import prox_elasticnet\n",
    "prox_en_vals = prox_elasticnet(v, lam, alpha)\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(v, prox_l1_vals, label=\"prox_l1\", color=\"crimson\")\n",
    "plt.plot(v, v, '--', color='gray', alpha=0.5)\n",
    "plt.title(\"ℓ₁ Prox (Soft-Thresholding)\")\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(v, prox_l2_vals, label=\"prox_l2\", color=\"seagreen\")\n",
    "plt.plot(v, v, '--', color='gray', alpha=0.5)\n",
    "plt.title(\"ℓ₂ Prox (Shrinkage)\")\n",
    "plt.xlabel(\"Input\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(v, prox_en_vals, label=\"prox_elasticnet\", color=\"royalblue\")\n",
    "plt.plot(v, v, '--', color='gray', alpha=0.5)\n",
    "plt.title(\"Elastic Net Prox\")\n",
    "plt.xlabel(\"Input\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Comparison of Proximal Operators\", fontsize=14, y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Visualizing Proximity Operators (Soft-Thresholding and Shrinkage)\n",
    "\n",
    "We plot how different proximal operators transform input values.\n",
    "\n",
    "This helps interpret:\n",
    "- Soft-thresholding behavior of ℓ₁ (LASSO)\n",
    "- Shrinkage effect of ℓ₂ (Ridge)\n",
    "- The combined action of Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.linspace(-3, 3, 500)\n",
    "lam = 1.0\n",
    "alpha = 0.5\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(v, prox_l1(v, lam), label=\"prox_l1\")\n",
    "plt.title(\"Soft-thresholding (ℓ₁)\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(v, prox_l2(v, lam), label=\"prox_l2\")\n",
    "plt.title(\"Shrinkage (ℓ₂)\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "from prox.prox_elasticnet import prox_elasticnet\n",
    "plt.plot(v, prox_elasticnet(v, lam, alpha), label=\"prox_elasticnet\")\n",
    "plt.title(\"Elastic Net Prox\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d. ISTA/FISTA on Synthetic Data\n",
    "\n",
    "Before applying solvers to real data, we verify their behavior on a toy regression problem\n",
    "with a known solution, where ℓ₁-regularization is expected to induce sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create toy problem ---\n",
    "np.random.seed(0)\n",
    "m, n = 30, 50\n",
    "A_synth = np.random.randn(m, n)\n",
    "x_true = np.zeros(n)\n",
    "x_true[:5] = np.random.randn(5)\n",
    "b_synth = A_synth @ x_true + 0.1 * np.random.randn(m)\n",
    "\n",
    "# --- Run ISTA ---\n",
    "lam = 0.1\n",
    "L = np.linalg.norm(A_synth, 2) ** 2\n",
    "step_size = 1.0 / L\n",
    "\n",
    "result_ista = ista(\n",
    "    grad_f=lambda x: A_synth.T @ (A_synth @ x - b_synth),\n",
    "    prox_g=lambda x, t: prox_l1(x, lam * t),\n",
    "    x0=np.zeros(n),\n",
    "    step_size=step_size,\n",
    "    max_iter=200,\n",
    "    tol=1e-8,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "x_ista = result_ista[\"x\"]\n",
    "\n",
    "# --- Plot recovered vs true ---\n",
    "plt.stem(x_true, label=\"True\", markerfmt='o', use_line_collection=True)\n",
    "plt.stem(x_ista, label=\"Recovered (ISTA)\", markerfmt='x', use_line_collection=True)\n",
    "plt.title(\"ISTA Recovery on Sparse Synthetic Vector\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 2 — Solver Runner Utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Solver Runner\n",
    "\n",
    "This section defines the `run_solver` function, which:\n",
    "- Selects the appropriate solver (ISTA, FISTA, etc.)\n",
    "- Selects the correct proximity operator based on the regularization model\n",
    "- Runs the solver and collects performance metrics\n",
    "\n",
    "All solvers return:\n",
    "- Final solution `x`\n",
    "- Objective function history\n",
    "- Execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_solver(\n",
    "    method: str,\n",
    "    model: str,\n",
    "    A: np.ndarray,\n",
    "    b: np.ndarray,\n",
    "    lam: float,\n",
    "    alpha: float = 0.5,\n",
    "    step_size: float = None,\n",
    "    max_iter: int = 1000,\n",
    "    tol: float = 1e-6,\n",
    "    verbose: bool = False\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    method: 'ista', 'fista', 'gradient', 'lbfgs'\n",
    "    model: 'lasso', 'ridge', 'elasticnet'\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Define smooth loss and gradient ---\n",
    "    def loss_f(x):\n",
    "        return 0.5 * np.linalg.norm(A @ x - b) ** 2\n",
    "\n",
    "    def grad_f(x):\n",
    "        return A.T @ (A @ x - b)\n",
    "\n",
    "    # --- Define prox operator ---\n",
    "    if model == \"lasso\":\n",
    "        prox_g = lambda x, t: prox_l1(x, lam * t)\n",
    "    elif model == \"ridge\":\n",
    "        prox_g = lambda x, t: prox_l2(x, lam * t)\n",
    "    elif model == \"elasticnet\":\n",
    "        prox_g = lambda x, t: prox_elasticnet(x, lam * t, alpha)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model}\")\n",
    "\n",
    "    # --- Set step size if not given ---\n",
    "    if step_size is None:\n",
    "        # Safe choice for ISTA/FISTA: 1 / Lipschitz constant of grad_f\n",
    "        L = np.linalg.norm(A, ord=2) ** 2\n",
    "        step_size = 1.0 / L\n",
    "\n",
    "    # --- Select and run solver ---\n",
    "    start_time = time.time()\n",
    "\n",
    "    if method == \"ista\":\n",
    "        result = ista(\n",
    "            grad_f, prox_g, np.zeros(A.shape[1]),\n",
    "            step_size, max_iter, tol, verbose,\n",
    "            loss_f=loss_f, track_sparsity=True\n",
    "        )\n",
    "    elif method == \"fista\":\n",
    "        result = fista(\n",
    "            grad_f, prox_g, np.zeros(A.shape[1]),\n",
    "            step_size, max_iter, tol, verbose,\n",
    "            loss_f=loss_f, track_sparsity=True\n",
    "        )\n",
    "    elif method == \"gradient\":\n",
    "        result = gradient_descent(\n",
    "            grad_f, np.zeros(A.shape[1]),\n",
    "            step_size, max_iter, tol, verbose,\n",
    "            loss_f=loss_f\n",
    "        )\n",
    "    elif method == \"lbfgs\":\n",
    "        result = lbfgs_solver(A, b, lam, model=model)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method '{method}'\")\n",
    "\n",
    "    result[\"time\"] = time.time() - start_time\n",
    "    result[\"loss_f\"] = loss_f  # for evaluation\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 3 — Run Solvers on the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Solvers\n",
    "\n",
    "We now run the selected optimization algorithms on the chosen dataset.\n",
    "\n",
    "You can choose:\n",
    "- The regularization model (`lasso`, `ridge`, `elasticnet`)\n",
    "- The optimization method (`ista`, `fista`, `gradient`, `lbfgs`)\n",
    "- The regularization parameter `lambda`\n",
    "- (Optional) Elastic Net mixing parameter `alpha`\n",
    "\n",
    "The results include the final solution, convergence history, runtime, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "model = \"lasso\"           # 'lasso', 'ridge', 'elasticnet'\n",
    "method = \"fista\"          # 'ista', 'fista', 'gradient', 'lbfgs'\n",
    "lam = 0.1                 # regularization strength\n",
    "alpha = 0.5               # only used for elastic net\n",
    "\n",
    "# --- Run selected solver ---\n",
    "result = run_solver(\n",
    "    method=method,\n",
    "    model=model,\n",
    "    A=X_train,\n",
    "    b=y_train,\n",
    "    lam=lam,\n",
    "    alpha=alpha,\n",
    "    max_iter=1000,\n",
    "    tol=1e-6,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# --- Unpack results ---\n",
    "x_sol = result[\"x\"]\n",
    "history = result.get(\"history\", [])\n",
    "elapsed_time = result[\"time\"]\n",
    "\n",
    "print(f\"Final objective value: {history[-1] if history else 'N/A'}\")\n",
    "print(f\"Elapsed time: {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 4 — Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation\n",
    "\n",
    "Once the solver has produced a solution vector `x`, we evaluate its quality on the test set.\n",
    "\n",
    "We report:\n",
    "- Test Mean Squared Error (MSE)\n",
    "- Training MSE (optional)\n",
    "- Sparsity of the solution: percentage of near-zero elements in `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sparsity(x: np.ndarray, threshold: float = 1e-6) -> float:\n",
    "    return np.sum(np.abs(x) < threshold) / len(x)\n",
    "\n",
    "# --- Predict on test set ---\n",
    "y_pred = X_test @ x_sol\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "train_mse = mean_squared_error(y_train, X_train @ x_sol)\n",
    "sparsity = compute_sparsity(x_sol)\n",
    "train_loss = result[\"loss_f\"](x_sol)\n",
    "test_loss = 0.5 * np.linalg.norm(X_test @ x_sol - y_test) ** 2\n",
    "\n",
    "# --- Print metrics ---\n",
    "print(f\"Train Obj:  {train_loss:.4f}\")\n",
    "print(f\"Test Obj:   {test_loss:.4f}\")\n",
    "print(f\"Train MSE:  {train_mse:.4f}\")\n",
    "print(f\"Test MSE:   {test_mse:.4f}\")\n",
    "print(f\"Sparsity:   {sparsity * 100:.2f}%\")\n",
    "\n",
    "# --- Visualize nonzero pattern ---\n",
    "plt.figure(figsize=(10, 1.5))\n",
    "plt.stem(x_sol, markerfmt='.', use_line_collection=True)\n",
    "plt.title(\"Learned Coefficients (Nonzero Pattern)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Convergence and Sparsity Plots\n",
    "\n",
    "We visualize:\n",
    "- The convergence of the objective value over iterations\n",
    "- The sparsity of the solution (optional: per iteration if tracked)\n",
    "\n",
    "This helps assess:\n",
    "- The speed of convergence\n",
    "- The stability and smoothness of the solver trajectory\n",
    "- How aggressively each method induces sparsity (for LASSO/Elastic Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot objective function history ---\n",
    "if history:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history, label=f\"{method.upper()} - {model}\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective Value\")\n",
    "    plt.title(\"Convergence Curve\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No convergence history available to plot.\")\n",
    "sparsity_history = result.get(\"sparsity_history\", None)\n",
    "if sparsity_history:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(sparsity_history)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Sparsity (fraction of zeros)\")\n",
    "    plt.title(\"Sparsity Over Iterations\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Estimate convergence slope (log scale) ---\n",
    "if history and len(history) >= 20:\n",
    "    import scipy.stats as stats\n",
    "    last_vals = np.log(history[-20:])\n",
    "    slope, _, _, _, _ = stats.linregress(np.arange(len(last_vals)), last_vals)\n",
    "    print(f\"Estimated log-convergence rate (slope): {slope:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 6 — Summary & Multi-Solver Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Comparison\n",
    "\n",
    "To compare multiple solvers or models, we run several configurations and collect:\n",
    "\n",
    "- Final objective value\n",
    "- Runtime (in seconds)\n",
    "- Test MSE\n",
    "- Solution sparsity\n",
    "\n",
    "We display these results in a summary table for easy analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Benchmark Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"ista\", \"fista\", \"gradient\"]\n",
    "if model != \"lasso\":\n",
    "    methods.append(\"lbfgs\")\n",
    "model = \"lasso\"  # or 'ridge', 'elasticnet'\n",
    "lam = 0.1\n",
    "alpha = 0.5\n",
    "\n",
    "benchmark_results = []\n",
    "\n",
    "for method in methods:\n",
    "    print(f\"\\nRunning: {method.upper()}...\")\n",
    "    result = run_solver(\n",
    "        method=method,\n",
    "        model=model,\n",
    "        A=X_train,\n",
    "        b=y_train,\n",
    "        lam=lam,\n",
    "        alpha=alpha,\n",
    "        max_iter=1000,\n",
    "        tol=1e-6,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    x_sol = result[\"x\"]\n",
    "    y_pred = X_test @ x_sol\n",
    "    test_mse = mean_squared_error(y_test, y_pred)\n",
    "    sparsity = compute_sparsity(x_sol)\n",
    "    time_taken = result[\"time\"]\n",
    "    final_obj = result.get(\"history\", [None])[-1]\n",
    "\n",
    "    benchmark_results.append({\n",
    "        \"method\": method,\n",
    "        \"final_obj\": final_obj,\n",
    "        \"test_mse\": test_mse,\n",
    "        \"sparsity\": sparsity,\n",
    "        \"time (s)\": time_taken\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Show results as a DataFrame ---\n",
    "import pandas as pd\n",
    "\n",
    "df_results = pd.DataFrame(benchmark_results)\n",
    "df_results = df_results.sort_values(by=\"test_mse\")\n",
    "display(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
